---
description: Analyze PR review feedback with validation and provide prioritized response plan
allowed-tools: "*"
---

# Arc PR Respond - Validated Feedback Analysis

Parse, validate, and prioritize feedback from a reviewed GitHub PR: {{args}}

This command performs a two-pass analysis:
1. **Pass 1**: Fetch and categorize all feedback
2. **Pass 2**: Validate complex/uncertain items using ca-code-review-validator
3. **Synthesis**: Present finalized assessments with recommended priorities

---

## PREREQUISITE: Check for GitHub CLI

Check if `gh` is installed: `gh --version`

**If not found**, auto-install by detecting platform:

- **macOS**: `brew install gh` (if Homebrew available)
- **Linux**: `apt-get install gh` (Ubuntu/Debian) or `dnf install gh` (Fedora) or `pacman -S github-cli` (Arch)
- **Windows**: `winget install GitHub.cli` (Windows 11/10) or `choco install gh` (Chocolatey) or `scoop install gh` (Scoop)

After install: `gh auth login`

If auto-install unavailable: https://cli.github.com

---

## PASS 1: Fetch and Categorize Feedback

### Step 1.1: Fetch All PR Feedback

**CRITICAL**: You MUST fetch ALL three types of comments separately:

1. **General PR reviews**: `gh pr view <number> --json reviews,comments`
2. **Inline code comments**: `gh api repos/{owner}/{repo}/pulls/{number}/comments`
3. **Issue comments**: `gh api repos/{owner}/{repo}/issues/{number}/comments`

Parse the PR URL to extract owner, repo, and number for API calls.

**DO NOT** rely only on `gh pr view` - it may not include all inline comments.

### Step 1.2: Parse Reviewer Arguments

From `{{args}}`:
- Extract PR URL/number
- Extract reviewer filter if specified:
  - `humans` - Exclude all bot comments (CodeRabbit, github-actions, etc.)
  - `<name>` - Only include feedback from specific reviewer(s)
  - Default - Include all feedback including bots

Examples:
- `/arc-pr-respond https://github.com/owner/repo/pull/123` - All feedback
- `/arc-pr-respond 123 humans` - Only human reviewers
- `/arc-pr-respond 123 brian` - Only Brian's feedback
- `/arc-pr-respond 123 michael brian` - Michael and Brian's feedback

### Step 1.3: Initial Categorization

For each feedback item, create an initial assessment:

```markdown
## Pass 1: Initial Categorization

**Item ID**: [Letter+Number, e.g., A1, A2, B1, B2]
**Reviewer**: [Name]
**Location**: [file:line or "General comment"]
**Feedback**: [Full feedback text]

**Initial Category**:
- [ ] Question - Reviewer asking for clarification
- [ ] Bug Report - Reviewer identified potential bug
- [ ] Suggestion - Improvement or alternative approach proposed
- [ ] Praise - Positive feedback
- [ ] Style/Formatting - Code style or formatting preference
- [ ] Documentation - Missing or incorrect documentation
- [ ] Testing - Missing or inadequate tests
- [ ] Performance - Performance concern
- [ ] Security - Security vulnerability or concern

**Complexity**:
- [ ] Simple - Obvious issue or straightforward question (typo, clear bug, simple question)
- [ ] Moderate - Involves judgment or trade-offs
- [ ] Complex - Requires deep analysis or has unclear validity

**Initial Validity Assessment**:
- [ ] Clearly Valid - Obvious issue or good suggestion
- [ ] Clearly Invalid - Based on misunderstanding or incorrect assumption
- [ ] Uncertain - Needs deeper analysis to assess
```

### Step 1.4: Identify Items Needing Validation

Review all categorized items and mark which need validation:

**MUST VALIDATE** (these warrant ca-code-review-validator assessment):
- Complexity is Moderate or Complex
- Initial Validity is Uncertain
- Category is Suggestion with trade-offs
- Category is Performance or Security (need to verify severity)
- Architectural feedback or design decisions
- Feedback that contradicts your understanding

**DO NOT VALIDATE** (these are obvious - skip to save time):
- Complexity is Simple AND Initial Validity is Clearly Valid
  - Examples: Typo fixes, obvious bugs, clear questions, missing semicolons
- Complexity is Simple AND Initial Validity is Clearly Invalid
  - Examples: Feedback based on clear misunderstanding of code
- Category is Praise (no action needed)
- Style/Formatting that's clearly subjective (just acknowledge)

Create a list:
```markdown
## Items for Validation (Pass 2)
- A1, A3, A5, B2, B4 [5 items total]

## Items Not Needing Validation (Already Clear)
- A2 (typo fix), A4 (clear question), B1 (praise), B3 (obvious bug)
```

---

## PASS 2: Validate Complex Feedback

### Step 2.1: Run Batch Validation

Compile all feedback items identified in Step 1.4 into a single list and invoke ca-code-review-validator agent **once**:

**Use the Task tool with the complete list**:

```
Review the following list of code review feedback items I received on my PR and validate them:

**Item A1**
File: [file:line]
Category: [Initial category from Step 1.3]
Complexity: [Simple/Moderate/Complex from Step 1.3]
Feedback: "[Complete feedback text]"

**Item A3**
File: [file:line]
Category: [Initial category]
Complexity: [Complexity level]
Feedback: "[Complete feedback text]"

[... all items needing validation ...]

Context: I'm the PR author trying to understand which feedback to prioritize. My PR is attempting to: [brief description of PR goal]
```

### Step 2.2: Process Batch Validation Results

The ca-code-review-validator will return batch results organized as:
- **Items to KEEP**: Valid feedback to address (âœ… FULLY ENDORSE / âš ï¸ ENDORSE WITH CAVEATS)
- **Items to REMOVE**: Invalid feedback or nitpicks (âŒ DISAGREE / ğŸ”µ MINOR/NITPICK / ğŸ¯ OUT OF SCOPE)
- **Items Needing Clarification**: Unclear feedback (ğŸ¤” DEPENDS/CLARIFY)

Extract the verdicts before proceeding to synthesis.

---

## SYNTHESIS: Finalized Feedback Analysis

### Step 3.1: Synthesize Each Feedback Item

For each feedback item (both validated and non-validated), create final assessment:

**Format** (use bold headers with separator lines for visibility):

```markdown
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
**A1. [Reviewer Name] - [Brief summary of feedback point]**

**Location**: `file:line` (or "General comment")

**Feedback**:
[Full feedback text from reviewer]

**Assessment**: [âœ… Valid / âš ï¸ Partially Valid / âŒ Invalid / ğŸ”µ Minor/Nitpick / ğŸ’¬ Question]

**Reasoning**:
[Your assessment with validator insights if validated]
[If validated: Note key points from ca-code-review-validator]

**Priority**: [ğŸ”´ High / ğŸŸ¡ Medium / ğŸŸ¢ Low / âšª No Action]

**Recommended Response**:
[Draft response to reviewer]

**Recommended Action**:
[What you should actually do: Fix the code / Add comment / Clarify in response / Acknowledge / No change needed]
```

#### Assessment Categories:

- **âœ… Valid**: Feedback is correct and should be addressed
  - Use for: Actual bugs, missing tests, real security issues, good suggestions

- **âš ï¸ Partially Valid**: Has merit but involves trade-offs or context
  - Use for: Suggestions with pros/cons, subjective improvements, context-dependent issues

- **âŒ Invalid**: Based on misunderstanding or incorrect assumptions
  - Use for: Feedback that's factually wrong or misunderstands the code

- **ğŸ”µ Minor/Nitpick**: Technically correct but very minor
  - Use for: Style preferences, naming suggestions, minor formatting

- **ğŸ’¬ Question**: Reviewer asking for information/clarification
  - Use for: All questions (separate from validity assessment)

#### Priority Levels:

- **ğŸ”´ High**: Must address before merge (security, bugs, breaking changes, critical tests)
- **ğŸŸ¡ Medium**: Should address (good suggestions, moderate issues, important questions)
- **ğŸŸ¢ Low**: Nice to have (minor improvements, style tweaks, low-impact suggestions)
- **âšª No Action**: Acknowledge but don't change (invalid feedback, out-of-scope, already handled)

### Step 3.2: Synthesis Guidelines

**For items NOT validated** (simple/obvious):
- Provide your own straightforward assessment
- Example: "Valid - This is a typo that should be fixed"
- Example: "Invalid - This code path is actually tested in integration-test.js:45"

**For items validated as âœ… FULLY ENDORSE**:
- Assessment: âœ… Valid
- Priority: Usually ğŸ”´ High or ğŸŸ¡ Medium
- Include validator's key reasoning if it adds value
- Example note: "(Validator confirmed: This could cause data corruption)"

**For items validated as âš ï¸ ENDORSE WITH CAVEATS**:
- Assessment: âš ï¸ Partially Valid
- Priority: Usually ğŸŸ¡ Medium or ğŸŸ¢ Low
- Include validator's trade-offs analysis
- Example note: "(Trade-off: Improves readability but adds 10ms latency)"

**For items validated as âŒ DISAGREE**:
- Assessment: âŒ Invalid
- Priority: âšª No Action
- Include validator's reasoning why feedback is incorrect
- Draft response explaining the misunderstanding politely

**For items validated as ğŸ”µ MINOR/NITPICK**:
- Assessment: ğŸ”µ Minor/Nitpick
- Priority: ğŸŸ¢ Low or âšª No Action
- Note it's subjective/low priority
- Keep response brief

**For items validated as ğŸ¤” DEPENDS/CLARIFY**:
- Assessment: ğŸ’¬ Question (treat as question needing more context)
- Priority: ğŸŸ¡ Medium (need to clarify)
- Draft response asking for clarification based on validator's questions

---

## FINAL OUTPUT: Complete Feedback Analysis

### Output Format:

```markdown
# PR Feedback Analysis: [PR Title]

## ğŸ“Š Overview

**Total Feedback Items**: [N]
**By Reviewer**:
- [Reviewer A]: [count] items
- [Reviewer B]: [count] items

**By Priority**:
- ğŸ”´ High: [count] items
- ğŸŸ¡ Medium: [count] items
- ğŸŸ¢ Low: [count] items
- âšª No Action: [count] items

**Validated Items**: [count] items were validated using ca-code-review-validator

---

## ğŸ“‹ Detailed Feedback Analysis

[For each feedback item, use the format from Step 3.1 above]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
**A1. [Reviewer] - [Summary]**
[Full analysis as specified above]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
**A2. [Reviewer] - [Summary]**
[Full analysis...]

---

## ğŸ¯ Recommended Action Plan

### Priority 1: Address Before Merge (ğŸ”´ High Priority)

1. **[Item ID]** - [Brief description]
   - **What to do**: [Specific action]
   - **File**: [file:line if applicable]

2. **[Item ID]** - [Brief description]
   - **What to do**: [Specific action]
   - **File**: [file:line if applicable]

### Priority 2: Should Address (ğŸŸ¡ Medium Priority)

1. **[Item ID]** - [Brief description]
   - **What to do**: [Specific action]

### Priority 3: Nice to Have (ğŸŸ¢ Low Priority)

1. **[Item ID]** - [Brief description]
   - **What to do**: [Specific action]

### Responses Only (âšª No Code Changes)

1. **[Item ID]** - [Brief description]
   - **What to do**: Post response to explain/acknowledge

---

## ğŸ’¬ Draft Responses Ready to Post

[For items needing responses, provide copy-pasteable responses]

**Response to Item A1**:
```
[Draft response text that can be copied directly to GitHub]
```

**Response to Item A3**:
```
[Draft response text]
```

---

## âœ… Quick Checklist

Before responding:
- [ ] All ğŸ”´ High Priority items have action plans
- [ ] All questions (ğŸ’¬) have responses drafted
- [ ] Invalid feedback (âŒ) has polite explanations prepared
- [ ] Trade-offs noted for âš ï¸ Partially Valid items

---

## ğŸ“ Summary

[2-3 paragraph summary including:]
- Overall quality of feedback received
- Key themes (security, testing, performance, style)
- Major items to address
- Any feedback that was validated and what validator found
```

---

## Important Notes

### Efficiency Considerations
- **Selective validation**: Only validate 20-40% of items (complex/uncertain ones)
- **Batch validation**: Single validator call processes entire list at once
- **Skip obvious items**: Don't waste time validating typos or clear bugs
- **Smart triage**: Validator does quick sanity checks on most items, deep investigation only when needed

### Response Tone
- **Professional and appreciative**: Thank reviewers for their time
- **Clear explanations**: When disagreeing, explain why politely
- **Acknowledge trade-offs**: For partially valid feedback, note what you're choosing and why
- **Ask questions**: When unclear, ask for clarification rather than assuming
- **DO NOT give time estimates**: Never estimate how long fixes will take - that's outside the scope of this command

### Validator Usage
The ca-code-review-validator provides:
- **Objective assessment**: Removes emotional response to criticism
- **Evidence-based reasoning**: Backs up assessments with code analysis
- **Trade-off analysis**: Helps understand implications of changes
- **Confidence boost**: When feedback is wrong, validator confirms it

### Output Cleanliness
- Use bold headers with separator lines (visible in Claude Code)
- DO NOT use ### headings (render as faint gray)
- Group feedback by reviewer (letter system: A1, A2, B1, B2)
- Keep format consistent across all items
- Make priorities visually distinct with emojis

### Examples of Simple vs Complex Feedback

**Simple (don't validate)**:
- "Typo on line 45: 'teh' should be 'the'"
- "Missing semicolon on line 67"
- "This variable is declared but never used"
- "Can you explain why you chose approach X?"

**Complex (do validate)**:
- "This could cause performance issues at scale"
- "Consider using pattern X instead of Y for better maintainability"
- "This might be vulnerable to XSS"
- "The error handling here seems insufficient"
